{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gold_text, gold_rationales\n",
    "# load transcript\n",
    "import json\n",
    "\n",
    "filepath = \"/mnt/hdd4/jinmyeong/hts_data/[FINAL-v7].json\"\n",
    "\n",
    "with open(filepath, 'r') as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_id': '1118579093153382400_twitter',\n",
       " 'sentence': ['mmh', 'alsterwasser', 'grapefruit'],\n",
       " 'intervals': {'intervals [1]': {'xmin': 0.0, 'xmax': 0.25, 'text': 'mmh'},\n",
       "  'intervals [2]': {'xmin': 0.25, 'xmax': 1.05, 'text': 'alsterwasser'},\n",
       "  'intervals [3]': {'xmin': 1.05, 'xmax': 1.58, 'text': 'grapefruit'}},\n",
       " 'rationale': [],\n",
       " 'label': 'normal'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_rationales_data = {}\n",
    "for audio_datapoint in data:\n",
    "    audio_id = audio_datapoint['audio_id']\n",
    "    audio_rationales_data[audio_id] = audio_datapoint\n",
    "file_path = '/home/jinmyeong/code/hts/classifier/Data/audio_rationales_data.json'\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(audio_rationales_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/jinmyeong/code/hts/classifier/Data/gold_hatemm_audioHateXplain.json\", \"r\") as f:\n",
    "    audio_rationales_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 0.149, 'end': 3.339, 'text': ' User, why would anyone watch wigger garbage like this show in the beginning?', 'words': [{'word': 'User,', 'start': 0.149, 'end': 0.41, 'score': 0.915}, {'word': 'why', 'start': 0.49, 'end': 0.631, 'score': 0.998}, {'word': 'would', 'start': 0.651, 'end': 0.811, 'score': 0.847}, {'word': 'anyone', 'start': 0.872, 'end': 1.172, 'score': 0.944}, {'word': 'watch', 'start': 1.213, 'end': 1.433, 'score': 0.873}, {'word': 'wigger', 'start': 1.493, 'end': 1.754, 'score': 0.886}, {'word': 'garbage', 'start': 1.794, 'end': 2.155, 'score': 0.923}, {'word': 'like', 'start': 2.215, 'end': 2.376, 'score': 0.834}, {'word': 'this', 'start': 2.416, 'end': 2.576, 'score': 0.912}, {'word': 'show', 'start': 2.617, 'end': 2.797, 'score': 0.911}, {'word': 'in', 'start': 2.837, 'end': 2.897, 'score': 0.748}, {'word': 'the', 'start': 2.917, 'end': 2.998, 'score': 0.833}, {'word': 'beginning?', 'start': 3.018, 'end': 3.339, 'score': 0.935}]}]\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "with open('/home/jinmyeong/code/hts/classifier/Data/new_post_id_divisions.json', 'r') as fp:\n",
    "    post_id_division = json.load(fp)\n",
    "\n",
    "with open('/home/jinmyeong/code/hts/ASR/Data/ASR/whisperX_ASR_transcription_v4-HateSpeech-all-multispeaker.json', 'r') as fp:\n",
    "    transcript_dict = json.load(fp)\n",
    "\n",
    "print(transcript_dict[\"1178765655790755845_twitter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "\n",
    "with open('/home/jinmyeong/code/hts/classifier/Data/hatemm_post_id_divisions.json', 'r') as fp:\n",
    "    post_id_division = json.load(fp)\n",
    "\n",
    "with open('/home/jinmyeong/code/hts/ASR/Data/ASR/whisperX_ASR_transcription_hatemm_hate.json', 'r') as fp:\n",
    "    transcript_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m gold_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(gold_word_list)\n\u001b[1;32m     12\u001b[0m gold_rationales \u001b[39m=\u001b[39m audio_datapoint[\u001b[39m'\u001b[39m\u001b[39mrationale\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m transcript \u001b[39m=\u001b[39m transcript_dict[test_id][\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m:]\n\u001b[1;32m     15\u001b[0m transcript_word_list \u001b[39m=\u001b[39m [word[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m transcript_dict[test_id][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     17\u001b[0m \u001b[39m# transcript_rationales 0으로 초기화\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "id_list = post_id_division['train'] + post_id_division['val'] + post_id_division['test']\n",
    "\n",
    "transcript_rationales_dict = {}\n",
    "\n",
    "for test_id in id_list:\n",
    "    if audio_rationales_data.get(test_id):\n",
    "        audio_datapoint = audio_rationales_data[test_id]\n",
    "\n",
    "        audio_id = audio_datapoint['audio_id']\n",
    "        gold_word_list = audio_datapoint['sentence']\n",
    "        gold_text = \" \".join(gold_word_list)\n",
    "        gold_rationales = audio_datapoint['rationale']\n",
    "\n",
    "        transcript = transcript_dict[test_id][0]['text'][1:]\n",
    "        transcript_word_list = [word['word'] for word in transcript_dict[test_id][0]['words']]\n",
    "\n",
    "        # transcript_rationales 0으로 초기화\n",
    "        len_transcript_word = len(transcript_word_list)\n",
    "        len_transcript_rationales = len(gold_rationales)\n",
    "\n",
    "        transcript_rationales = [len_transcript_word * [0] for _ in range(len_transcript_rationales)]\n",
    "\n",
    "        error = jiwer.process_words(gold_text, transcript)\n",
    "        alignments = error.alignments[0]\n",
    "\n",
    "        for alignment in alignments:\n",
    "            align_type = alignment.type\n",
    "            ref_start_idx = alignment.ref_start_idx\n",
    "            ref_end_idx = alignment.ref_end_idx\n",
    "            hyp_start_idx = alignment.hyp_start_idx\n",
    "            hyp_end_idx = alignment.hyp_end_idx\n",
    "\n",
    "            # align이 맞을 경우, ref의 rationale을 hyp에 넣는다.\n",
    "            for idx, gold_rationale in enumerate(gold_rationales):\n",
    "                if align_type=='equal':\n",
    "                    transcript_rationales[idx][hyp_start_idx:hyp_end_idx] = gold_rationale[ref_start_idx:ref_end_idx]\n",
    "                    \n",
    "        transcript_rationales_dict[audio_id] = transcript_rationales\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/jinmyeong/code/hts/classifier/Data/transcript_rationales.json'\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(transcript_rationales_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Come to an amicable agreement and resolution with the non-Kurdish Iraqi herd of instances of Iraqi Arabs being barred from returning to their homes in Kirkuk.\n",
      "['Come', 'to', 'an', 'amicable', 'agreement', 'and', 'resolution', 'with', 'the', 'non-Kurdish', 'Iraqi', 'herd', 'of', 'instances', 'of', 'Iraqi', 'Arabs', 'being', 'barred', 'from', 'returning', 'to', 'their', 'homes', 'in', 'Kirkuk.']\n"
     ]
    }
   ],
   "source": [
    "print(transcript_rationales_dict[\"25502565_gab\"])\n",
    "transcript = transcript_dict[\"25502565_gab\"][0]['text'][1:]\n",
    "print(transcript)\n",
    "transcript_word_list = [word['word'] for word in transcript_dict[\"25502565_gab\"][0]['words']]\n",
    "print(transcript_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['come', 'to', 'an', 'amicable', 'agreement', 'and', 'resolution', 'with', 'the', 'non', 'kurdish', 'iraqi', 'heard', 'of', 'instances', 'of', 'iraqi', 'arabs', 'being', 'barred', 'from', 'returning', 'to', 'their', 'homes', 'in', 'kirkuk']\n"
     ]
    }
   ],
   "source": [
    "audio_datapoint = audio_rationales_data[\"25502565_gab\"]\n",
    "gold_rationales = audio_datapoint['rationale']\n",
    "print(gold_rationales)\n",
    "print(audio_datapoint['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
